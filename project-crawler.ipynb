{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import search\n",
    "import urllib\n",
    "import urllib.request\n",
    "import re\n",
    "import _thread\n",
    "import time\n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "defaultencoding = 'utf-8'\n",
    "if sys.getdefaultencoding() != defaultencoding:\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding(defaultencoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GHCrawler:\n",
    "#initialization\n",
    "    def __init__(self):\n",
    "        self.pageIndex = 1\n",
    "        self.user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'\n",
    "        #initialize headers\n",
    "        self.headers = { 'User-Agent' : self.user_agent }\n",
    "        #every pages' stories\n",
    "        self.stories = []\n",
    "        #if continue\n",
    "        self.enable = False\n",
    "        \n",
    "    #get pages' code\n",
    "    def getPage(self,pageIndex,language_type,search_content):\n",
    "        #print project_number,sort_options,search_content+\"=========\"\n",
    "        try:\n",
    "            #url = 'http://www.qiushibaike.com/hot/page/' + str(pageIndex)\n",
    "            #url = 'https://github.com/search?o=desc&q=big+data&s=stars&p='+str(pageIndex)\n",
    "            # url = 'https://github.com/search?'+str(sort_options)+'&q='+str(search_content)+'&p='+str(pageIndex)\n",
    "            url = 'https://github.com/search?l='+str(language_type)+'&p='+str(pageIndex)+'&q='+str(search_content)+'&type=Code'\n",
    "            # https://github.com/search?l=Java&p=3&q=search+engine&type=Code\n",
    "            print(url)\n",
    "            #construct request\n",
    "            request = urllib.request.Request(url,headers = self.headers)\n",
    "            #urlopen to get codes\n",
    "            response = urllib.request.urlopen(request)\n",
    "            #UTF-8 transform\n",
    "            pageCode = response.read().decode('utf-8')\n",
    "            return pageCode\n",
    "        except urllib.request.URLError:\n",
    "            print(\"Connecting github failed\")\n",
    "            return None\n",
    "        \n",
    "    def getPage_login(self,pageIndex,language_type,search_content):\n",
    "        r1 = requests.get(\n",
    "        url='https://github.com/login')\n",
    "        s1 = BeautifulSoup(r1.text, 'html.parser')\n",
    "        token = s1.find(name='input', attrs={'name': 'authenticity_token'}).get('value')\n",
    "        r1_cookie_dict = r1.cookies.get_dict()\n",
    "        r2 = requests.post(\n",
    "        url='https://github.com/session',\n",
    "        data={\n",
    "        'commit':'Sign in',\n",
    "        'utf8':'✓',\n",
    "        'authenticity_token':token,\n",
    "        'login':'630853543@qq.com',\n",
    "        'password':'***'  \n",
    "        },\n",
    "        cookies=r1_cookie_dict\n",
    "        )\n",
    "        r2_cookie_dict = r2.cookies.get_dict()\n",
    "        url='https://github.com/search?l='+str(language_type)+'&p='+str(pageIndex)+'&q='+str(search_content)+'&type=Code'\n",
    "        r3 = requests.get(\n",
    "        url,\n",
    "        cookies=r2_cookie_dict\n",
    "        )\n",
    "        print(url)\n",
    "        pageCode = r3.text\n",
    "        return pageCode\n",
    "        \n",
    "        \n",
    "        \n",
    "    def getPageItems(self,pageIndex,language_type,search_content):\n",
    "        #print project_number,sort_options,search_content+\"====\"\n",
    "        pageCode = self.getPage_login(pageIndex,language_type,search_content)\n",
    "        #print pageCode\n",
    "        if not pageCode:\n",
    "            print(\"Page loading failed....\")\n",
    "            return None\n",
    "        \n",
    "        # reg = '&quot;url&quot;:&quot;.+?&quot;},&quot;originating_url&quot;:&quot;'\n",
    "        reg = '<div class=\"f4 text-normal\">.+?<div class=\"file-box blob-wrapper my-1\">'\n",
    "        pattern = re.compile(reg,re.S)\n",
    "        items = re.findall(pattern,pageCode)\n",
    "        \n",
    "        urls = []\n",
    "        for item in items:\n",
    "            soup = BeautifulSoup(item, 'html.parser')\n",
    "            urls.append('https://raw.githubusercontent.com'+soup.find('a')['href'].replace('blob/',''))\n",
    "            # urls.append(item.strip('&quot;url&quot;:&quot;').strip('&quot;},&quot;originating_'))\n",
    "        \n",
    "        return urls\n",
    "    \n",
    "    def loadPage(self,pageIndex,language_type,search_content):\n",
    "        #print project_number,sort_options,search_content\n",
    "        pageUrls = self.getPageItems(self.pageIndex,language_type,search_content)\n",
    "        for pageurl in pageUrls:\n",
    "            self.stories.append(pageurl)\n",
    "            \n",
    "    def getCode(self, url):\n",
    "        c = requests.get(url)\n",
    "        code = c.text\n",
    "        #request = urllib.request.Request(url,headers = self.headers)\n",
    "        #urlopen to get codes\n",
    "        #response = urllib.request.urlopen(request)\n",
    "        #code = response.read().decode('gdk')\n",
    "        return code\n",
    "    \n",
    "    def start_crawler(self,page_number,language_type,search_content):\n",
    "        print(u\"Reading github pages，Search for \"+search_content)\n",
    "        #print project_number,sort_options,search_content\n",
    "        self.enable = True\n",
    "        while self.pageIndex <= page_number:\n",
    "            self.loadPage(self.pageIndex,language_type,search_content)\n",
    "            self.pageIndex += 1\n",
    "        print('\\n')\n",
    "        count = 1\n",
    "        for i in self.stories:\n",
    "            print(i)\n",
    "            codefile = self.getCode(str(i))\n",
    "            f = open('./data/Code %d.txt'%count,'wt',encoding='utf-8') #output.txt - 文件名称及格式 w - writing\n",
    "            f.write(codefile)\n",
    "            f.close()\n",
    "            count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider = GHCrawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language type: Java\n",
      "Reading github pages，Search for search+engine\n",
      "https://github.com/search?l=Java&p=1&q=search+engine&type=Code\n",
      "https://github.com/search?l=Java&p=2&q=search+engine&type=Code\n",
      "\n",
      "\n",
      "https://raw.githubusercontent.com/qiaohhgz/hotel/648bf684a053b3afda0edc531b77038420fc4928/src/main/java/hotel/common/constant/SearchEngineIDT.java\n",
      "https://raw.githubusercontent.com/haytham-salhi/Spread/a3793a45be6c6fd2a327627b71d3b693cfc4b5a1/src/main/java/com/spread/persistence/rds/repository/SearchResultRepository.java\n",
      "https://raw.githubusercontent.com/OptiPop/packages_apps_Browser/fd3a31588f283de64309895170f5ce29039a60b4/src/com/android/browser/search/SearchEngines.java\n",
      "https://raw.githubusercontent.com/Macheal2/Browser/b8ac33371093297a1466989264e7877bae9a3340/src/com/android/browser/search/SearchEngines.java\n",
      "https://raw.githubusercontent.com/liferay/liferay-central-test-2/92d21ade0e059deb1bb0cf5cef5e8b9ddf5d3637/portal-kernel/src/com/liferay/portal/kernel/search/AbstractSearchEngineConfigurator.java\n",
      "https://raw.githubusercontent.com/liferay/liferay-central-test-2/92d21ade0e059deb1bb0cf5cef5e8b9ddf5d3637/modules/apps/foundation/portal-search/portal-search/src/main/java/com/liferay/portal/search/internal/SearchEngineHelperImpl.java\n",
      "https://raw.githubusercontent.com/liferay/liferay-central-test-2/92d21ade0e059deb1bb0cf5cef5e8b9ddf5d3637/portal-kernel/src/com/liferay/portal/kernel/search/SearchEngineHelperUtil.java\n",
      "https://raw.githubusercontent.com/HassanHamdy/chromiumUpdate/f1d2e5251cf413a42d2075b8005dd72c2645db2c/app/src/main/java/org/chromium/chrome/browser/search_engines/SearchEngineType.java\n",
      "https://raw.githubusercontent.com/unkascrack/compass-fork/25d4f4b816d1e480a5f5ff26f36cb821e3f28afb/compass-core/src/test/java/org/compass/core/test/engine/lucene/transaction/AbstractTransactionEngineTests.java\n",
      "https://raw.githubusercontent.com/LineageOS/android_packages_apps_Gello/2cbe2dde0a8de90e278cddcf5f293b0f5f09d012/src/com/android/browser/mdm/tests/SearchRestrictionsTest.java\n",
      "https://raw.githubusercontent.com/liferay/liferay-portal/c8a983065875bcad76254eb125cf75b902a6cde4/portal-kernel/src/com/liferay/portal/kernel/search/BaseSearchEngineConfigurator.java\n",
      "https://raw.githubusercontent.com/champagneguo/Browser/832fc1f3611765cfdaf130f6f2b828c47e1038d1/src/com/android/browser/search/SearchEngines.java\n",
      "https://raw.githubusercontent.com/marceloagmelo/prodevelopment/ffd74001ac6245c676b7c8cd76ed842bbac753bc/portal/liferay-portal-6.1.1-ce-ga2/workspace/liferay-portal-src-6.1.1-ce-ga2/portal-service/src/com/liferay/portal/kernel/search/AbstractSearchEngineConfigurator.java\n",
      "https://raw.githubusercontent.com/EBI-IntAct/intact-google-import/285883503f0818778d3e7aae7427b87e95f401ea/repo/data-exchange/branches/data-exchange-2.0.0.1/psimi/psimitab/intact-psimitab/src/test/java/uk/ac/ebi/intact/psimitab/search/IntActSearchEngineTest.java\n",
      "https://raw.githubusercontent.com/EBI-IntAct/intact-google-import/285883503f0818778d3e7aae7427b87e95f401ea/repo/data-exchange/branches/data-exchange-2.0.0.x/psimi/psimitab/intact-psimitab/src/test/java/uk/ac/ebi/intact/psimitab/search/IntActSearchEngineTest.java\n",
      "https://raw.githubusercontent.com/EBI-IntAct/intact-google-import/285883503f0818778d3e7aae7427b87e95f401ea/repo/data-exchange/tags/dataexchange-master-2.0.0/psimi/psimitab/intact-psimitab/src/test/java/uk/ac/ebi/intact/psimitab/search/IntActSearchEngineTest.java\n",
      "https://raw.githubusercontent.com/EBI-IntAct/intact-google-import/285883503f0818778d3e7aae7427b87e95f401ea/repo/data-exchange/branches/data-exchange-2.0.1.x/psimi/psimitab/intact-psimitab/src/test/java/uk/ac/ebi/intact/psimitab/search/IntActSearchEngineTest.java\n",
      "https://raw.githubusercontent.com/EBI-IntAct/intact-google-import/285883503f0818778d3e7aae7427b87e95f401ea/repo/data-exchange/tags/dataexchange-master-2.0.1/psimi/psimitab/intact-psimitab/src/test/java/uk/ac/ebi/intact/psimitab/search/IntActSearchEngineTest.java\n",
      "https://raw.githubusercontent.com/marceloagmelo/prodevelopment/ffd74001ac6245c676b7c8cd76ed842bbac753bc/portal/liferay-portal-6.2-ce-ga2/workspace/liferay-portal-src-6.2-ce-ga2/portal-service/src/com/liferay/portal/kernel/search/AbstractSearchEngineConfigurator.java\n",
      "https://raw.githubusercontent.com/fengcone/mainpage/4de32c936dae5083c99646d5c958090aeb58b167/src/main/java/fengcone/mainpage/service/search/SearchService.java\n"
     ]
    }
   ],
   "source": [
    "project_number = 20\n",
    "page_number = 2\n",
    "#0:most stars,1:fewest stars,2:most forks,3:fewest forks,4:recently updated,5:least recently updated\n",
    "options = 0\n",
    "language_type = 'Java'\n",
    "print('language type: '+language_type)\n",
    "#search content\n",
    "content = \"search engine\"\n",
    "search_content = content.replace(\" \", \"+\")\n",
    "spider.start_crawler(page_number,language_type,search_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
